---
title: 本地数据缓存
date: 2022-07-19 11:50:52
tags:
    - 缓存
categories:
    - CirroData
description:
    - CirroData 本地数据缓存功能，缓存远程读取的数据，提高再次访问相同数据的效率
---

## 各单号

| 主题 | 单号 |
| --- | --- |
| 数据缓存需求 | 31501 |
| 数据缓存测试大纲 | 32428 |
| 数据缓存sit | 36740 |
| 数据缓存优化需求 | 36258 |
| 数据缓存优化sit | 37616 |

## 配置参数

### 数据缓存

| 参数名 | 说明 | 参数类型 | 默认值 | 参数值范围 |
| --- | --- | --- | --- | --- |
| local_data_cache_dir | 配置缓存数据的存储目录的绝对路径和每个目录的容量大小的字符串,不同路径使用英文逗号隔开,使用英文冒号分割路径和容量大小,例如: data/0,/data/1:1TB.代表缓存最大2TB,/data/0 和 /data/1分别最大1TB. 请注意,主机上每个CirroData进程必须有唯一的数据缓存目录.默认为空,代表禁用. | string | 空 | 目录: 为空或存储目录数量大于等于1；容量: [4KB,4TB]（支持使用单位: K、KB、M、MB、G、GB、T、TB、P、PB、E、EB, 无单位默认为Byte,但要保证单位转换后的结果在取值范围内） |
| local_data_cache_enable | 是否为远程读开启数据缓存.若需要启用数据缓存,则同时需要配置local_data_cache_dir参数. | bool | false | true/false |
| local_data_cache_file_max_size | 缓存文件在停止追加数据前可以增加到的最大值,==不等于缓存文件最终大小==,建议与配置的缓存存储目录空间大小保持一致. | string | 1099511627776 | [4KB,4TB] |
| local_data_cache_max_file_num | 允许打开的最大文件数,不能小于指定数据缓存目录的数量.若有两个存储目录,则每个存储目录下最大可打开文件数为n/2. | int32 | 1000 | [数据缓存存储目录个数,int32_max] |
| local_data_cache_write_thread_num | 每个数据缓存目录允许插入数据的并发线程数. | int32 | 1 | (0,int32_max] |

{% note warning %}

#### 注意

若数据长度大于`local_data_cache_file_max_size`,则数据不会被缓存,数据缓存不支持拆分数据以存下超量数据
{% endnote %}

### 数据缓存优化

| 参数名 | 说明 | 参数类型 | 默认值 | 参数值范围 |
| --- | --- | --- | --- | --- |
| consistent_hashing_min_virtual_node_count | 数据缓存节点选择时一致性哈希的最小虚拟节点数. | int32 | 1000 | (0,5000) |
| local_data_cache_policy | 本地数据缓存策略.NO_CACHE: 不进行本地缓存 AUTO_CACHE: 自动选择节点进行缓存（最多选择两个） GLOBAL_CACHE: 所有节点都可以缓存, 属于动态参数 | string | auto_cache | no_cache,<br>auto_cache,<br>global_cache |

## 数据缓存规则

### 缓存文件缓存数据规则

1. 最新的缓存文件file_1不足以存放新数据data1时，缓存文件file_1停止追加新数据，新建缓存文件file_2缓存新数据data1
    - 一次写入缓存文件的数据,其判断是否可写入文件使用的大小是其数据大小扩展至页大小(4KB)的倍数.
    例如: 数据大小是512Byte,实际会扩展至4KB,即使file_1剩余空间大小是512Byte也会被认为不足以存放数据
2. 缓存容量已达上限，先从缓存文件中删除旧的数据，直到有足够空间存放新的数据，继续向缓存文件追加新数据

### 缓存文件删除时机

1. 行云停止或宕机时缓存文件会被删除
2. 总缓存文件数超过`local_data_cache_max_file_num`时,旧的缓存文件会被删除

#### 可缓存不代表全缓存, 以下情况数据不会被缓存

1. 待缓存数据长度大于`local_data_cache_file_max_size`不会被缓存
2. 受IO线程数影响,受到IO阻塞影响的数据,直接放弃写入缓存文件中,避免因阻塞导致查询耗时倍增
    - 可通过多次查询将因IO阻塞而未被缓存的数据写入到缓存文件中,即逐渐缓存全部可缓存数据的过程,查询会因缓存增加而耗时减少。**建议**
    - `local_data_cache_write_thread_num` 修改为64,会使得所有IO都用于缓存,可使在第一次查询时缓存所有可缓存数据。**不建议,会阻塞其他SQL执行**

### 不同缓存策略下缓存节点选择规则

{% tabs choose node, 2 %}
<!-- tab no cache -->
无可缓存节点
<!-- endtab -->

<!-- tab auto cache -->
1. 排除副本节点后,最多两个可缓存节点;
2. 优先使用已缓存数据占比少的节点,该节点会持有10分钟优先权,10分钟后才会按已缓存数据占比重新选择
3. 使用系统表`V$USER_TAB_CACHE_DISTR`查询同一个表的可缓存节点,也相当于一次表查询操作,会触发节点优先权计时,即查询前若使用`V$USER_TAB_CACHE_DISTR`查询表的可缓存节点,那么节点失去优先权倒计时已开始计时
<!-- endtab -->

<!-- tab global cache -->
1. 排除副本节点后的所有节点都为可缓存节点
2. 无节点上下线,保持长期使用一节点读取某文件的可缓存节点
<!-- endtab -->
{% endtabs %}

## 查询各节点缓存情况

``` sql
SELECT * FROM V$LOCAL_DATA_CACHE_STATUS;
```

## 查询某表的可缓存节点

{% tabs V$USER_TAB_CACHE_DISTR, 1 %}
<!-- tab systemadmin用户 -->

``` sql
SELECT * FROM V$USER_TAB_CACHE_DISTR WHERE DATABASE_NAME = 'database_name' AND SCHEMA_NAME = 'schema_name' AND TABLE_NAME = 'table_name';
```

<!-- endtab -->
<!-- tab system用户 -->

``` sql
SELECT * FROM V$USER_TAB_CACHE_DISTR WHERE SCHEMA_NAME = 'schema_name' AND TABLE_NAME = 'table_name';
```

<!-- endtab -->
<!-- tab 普通用户 -->

``` sql
SELECT * FROM V$USER_TAB_CACHE_DISTR WHERE TABLE_NAME = 'table_name';
```

<!-- endtab -->
{% endtabs %}

## 缓存文件

### 查看缓存文件文件

#### 精准查找

``` bash
lsof +L1 | grep "data-cache-${hostname}-${service_port}"
```

示例:

``` bash
lsof +L1 | grep "data-cache-cirrodata04-62622"
```

#### 模糊查找,适用多个节点一起看,不用更改`${hostname}`

``` bash
lsof +L1 | grep "data-cache" | grep "${service_port}"
```

示例:

``` bash
lsof +L1 | grep "data-cache" | grep "62622"
```

### 循环查看缓存文件数

每3秒打印一次缓存文件数

``` bash
while true; do lsof +L1 | grep -c "data-cache-${hostname}-${service_port}"; sleep 3; done
```

示例

``` bash
while true; do lsof +L1 | grep -c "data-cache-cirrodata04-62622"; sleep 3; done
```

## profile关键字

| 关键字 | 说明 |
| --- | --- |
| Remote Read Data Cache Hit Bytes | 从缓存中读取到的总字节数 |
| Remote Read Data Cache Hit Cnt | 命中缓存次数,即读缓存次数 |
| Remote Read Data Cache Miss Bytes | 多少字节是缓存中没有的 |
| Remote Read Data Cache Miss Cnt | 未命中缓存次数,即不是从缓存中读取的次数 |
| Remote Read Data Cache Partial Hit Cnt | 部分命中次数,有多少次读取有部分数据是从缓存中读的 |
| Remote Read Data Cache Read Time | 从缓存中读取总耗时 |
| Remote Read Data Cache Write Time | 写缓存数据总耗时 |

### 查看profile主要信息,日志过滤

``` bash
grep -aE "Sql Statement|Hdfs Remote Bytes Read|Hdfs Local Bytes Read|Remote Read Data Cache|Fragment-" ${profile_path}
```

示例1:

``` bash
grep -aE "Sql Statement|Hdfs Remote Bytes Read|Hdfs Local Bytes Read|Remote Read Data Cache|Fragment-" log/xcloudd.PROFILE
```

> 想看到较完整SQL可以添加 -A选项 -A4 表示也展示过滤行后的4行

示例2:

``` bash
grep -aEA4 "Sql Statement|Hdfs Remote Bytes Read|Hdfs Local Bytes Read|Remote Read Data Cache|Fragment-" log/PROFILE_.log20230423-110817.5028
```

### 如何判断是否使用数据缓存

1. 执行节点是可缓存节点
查看profile中[Fragment-](#查看profile主要信息日志过滤)后的节点是否在系统表[V$LOCAL_DATA_CACHE_STATUS](#查询各节点缓存情况)的`CACHE_NODES`列显示的节点中
2. profile中Remote Read Data Cache任意一项不为0即表示使用了数据缓存,而Remote Read Data Cache Miss Bytes 和 Remote Read Data Cache Write Time 不为0,则说明有写缓存（不代表最终会落盘,遵循[数据缓存规则](#数据缓存规则)）
3. local_data_cache_file_max_size配置足够大,否则即使有写缓存,但因数据过大实际不会缓存
